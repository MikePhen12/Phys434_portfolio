{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be working with truth tables are trying to understand fundamentally which scenario of mis-identification is worse. We want to ensure that we do properly ensure that we are properly identifying A bird with a bird and a person with a person, but NN's do not always do this. We want to ensure that if wrong identification does happen, we want to ensure that one scenario is not as bad as the other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1 using NN\n",
    "#          | True Bird  | True Person|\n",
    "#----------|------------|------------|\n",
    "#| NN Bird | 45         | 5          | \n",
    "#|NN Person| 3          | 47         | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 2 using NN\n",
    "#          | True Bird  | True Person|\n",
    "#----------|------------|------------|\n",
    "#| NN Bird | 47         | 11         | \n",
    "#|NN Person| 1          | 42         | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the truth table from the homeowrk, it is easy to see that Table 2 make more mistakes than Table 1. Table 2 makes 12 mistakes while Table 1 makes 8 mistakes. Given the circumstances of the and how huge each mistake would be, the better algorithm for the zoo would be Table 2. This allows the least amount of birds to escape even though it does end up closing at the wrong time and entrapping the human for 30 seconds. This new algorithm is a better bet when prioritizing the number of birds at the zoo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Table 1 using NN\n",
    "#          | True Bird  | True Person|\n",
    "#----------|------------|------------|\n",
    "#| NN Bird | 93.1       | .3         | \n",
    "#|NN Person| 5.9        | .7         | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Table 1 using NN\n",
    "#          | True Bird  | True Person|\n",
    "#----------|------------|------------|\n",
    "#| NN Bird | 97.2       | .4         | \n",
    "#|NN Person| 1.8        | .6         | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have made new truth tables above considering there is only 1% of people. The new algorithm shows that there are much fewer mistakes in general, but since there are more birds instead of humans, there is technically more birds that will escape just because of a bigger sample of birds vs humans. The algorithm, though, is better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ater doing some research on the exponential distribution on wikipedia here: https://en.wikipedia.org/wiki/Exponential_distribution, I found some interesting things. The first is that summing two identical exponential PDFs is resultant in an Erlang distribution. This has a shape equal to 2.0 the parameter equal to the rate, $\\lambda$, in the exponential distribution. This turns out to be a special case for gamma distribution. I found this WolfRamAlpha here: https://reference.wolfram.com/language/ref/GammaDistribution.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the ratio of two normal distributions is equal to a Cauchy distribution. The parameter is equal to the ratio of the two sigma values of the base functions. I found the information by going through the wikipedia page here: https://en.wikipedia.org/wiki/Normal_distribution#Related_distributions. The wikipedia claims that if ${\\displaystyle X,Y\\sim {\\textrm {N}}(0,1)\\,X,Y}X, Y \\sim \\textrm{N}(0,1)\\,$  with X, Y independent, then ${\\displaystyle {\\tfrac {X}{Y}}\\sim {\\textrm {Cauchy}}(0,1)\\,}{\\displaystyle {\\tfrac {X}{Y}}\\sim {\\textrm {Cauchy}}(0,1)\\,} $\n",
    "\n",
    "I was then able to veryify this by locating at the normal ration distribution found on wikipedia. I have attached the link here: https://en.wikipedia.org/wiki/Ratio_distribution#Normal_ratio_distributions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
